{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/TestImages.zip"
      ],
      "metadata": {
        "id": "7C76JHxtC01G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aVprIZFrCFl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __get_list_from_dict(self, data: dict, size_img):\n",
        "        result = []\n",
        "        keys = data.keys()\n",
        "        dx = size_img[0]/self.image_size[0]\n",
        "        dy = size_img[1]/self.image_size[1]\n",
        "        \n",
        "        result.append(int(data['ul'][0]/dy))\n",
        "        result.append(int(data['ul'][1]/dx))\n",
        "\n",
        "        result.append(int(data['br'][0]/dy))\n",
        "        result.append(int(data['br'][1]/dx)) \n",
        "        return result    "
      ],
      "metadata": {
        "id": "MU3rXynV-SKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "799Z5bliCkLm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import itertools, math\n",
        "import pandas\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow import keras \n",
        "import os\n",
        "from glob import glob\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# подготовка данных \n",
        "path_dataset = \"/content/TestImages\"\n",
        "path_dataset_list = os.listdir(path_dataset) \n",
        "\n",
        "path_images = sorted([ os.path.join(path_dataset,path_image) for path_image in path_dataset_list if path_image.split('.')[-1] == 'JPG'], key = lambda a:a[:-5])\n",
        "path_json =   sorted([os.path.join(path_dataset,path_json) for path_json in path_dataset_list if path_json.split('.')[-1] == 'json'], key = lambda a:a[:-5] )"
      ],
      "metadata": {
        "id": "n0L1nKp5nrkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# удаление потерянных файлов\n",
        "path_json_ = [i[:-5] for i in path_json]\n",
        "del_ = []\n",
        "for i in range(len(path_json)):\n",
        "    if not path_images[i] in path_json_:\n",
        "        del_.append(path_images[i])\n",
        "\n",
        "for path in del_:\n",
        "    path_images.remove(path)"
      ],
      "metadata": {
        "id": "DRroxKY6DJML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(path_json))\n",
        "print(len(path_images))"
      ],
      "metadata": {
        "id": "a7UqHEt9CCsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_images = sorted(path_images)\n",
        "path_json = sorted(path_json)"
      ],
      "metadata": {
        "id": "zBpWf_R2FB_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# разделение на тренировочную и обучающую выборку \n",
        "count_data = len(path_images)\n",
        "per = .75\n",
        "train_path_images = path_images[:int(per*count_data)]\n",
        "train_path_json = path_json[:int(per*count_data)]\n",
        "\n",
        "valid_path_images = path_images[int(per*count_data):]\n",
        "valid_path_json = path_json[int(per*count_data):]"
      ],
      "metadata": {
        "id": "uMIvE8XFAILm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_path_images)):\n",
        "    print(train_path_images[i], train_path_json[i])"
      ],
      "metadata": {
        "id": "g-ZhCF3gBnZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(count_data)\n",
        "print(len(train_path_images))\n",
        "print(len(valid_path_images))"
      ],
      "metadata": {
        "id": "L898aui8BYwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = x = cv2.imread(train_path_images[0])\n",
        "with open (train_path_json[0], 'r') as file:\n",
        "        data = json.load(file)\n",
        "print(data)\n",
        "cv2.circle(img, data['ul'],10,(255,0,0),-1)\n",
        "cv2.circle(img, data['ur'],10,(255,0,0),-1)\n",
        "cv2.circle(img, data['br'],10,(255,0,0),-1)\n",
        "cv2.circle(img, data['bl'],10,(255,0,0),-1)\n",
        "\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "PYA0busVW4F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "     #  генератор данных \n",
        "    def __init__(self, images_path_list, coords_path_list, batch_size, image_size = (512,512)): \n",
        " \n",
        "        self.image_size = image_size\n",
        "\n",
        "\n",
        "        self.images_path_list = sorted(images_path_list)\n",
        "        self.coords_path_list = sorted(coords_path_list)\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # кол-во пакетов в эпоху \n",
        "        return  int(np.ceil(len(self.images_path_list)/ self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # обновление индексов \n",
        "        self.indexes = np.arange(len(self.images_path_list))\n",
        "        # np.random.shuffle(self.indexes)\n",
        "\n",
        "    def read_image(self,path): \n",
        "        x = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
        "        x = cv2.resize(x, (512,512), cv2.INTER_CUBIC)\n",
        "        return x \n",
        "    \n",
        "    def get_point_in_json(self, path_json):\n",
        "        point = []\n",
        "        img = cv2.imread(path_json[:-5],cv2.IMREAD_GRAYSCALE)\n",
        "        h,w = img.shape\n",
        "        with open (path_json, 'r') as file:\n",
        "            data = json.load(file)\n",
        "            point = self.__get_list_from_dict(data, (h,w))\n",
        "        return point\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index): \n",
        "        indexes = self.indexes[index *self.batch_size : (index+1)* self.batch_size]\n",
        "\n",
        "        image = tf.convert_to_tensor([self.read_image(self.images_path_list[k])/255.0 for k in indexes], dtype= tf.float64)\n",
        "        coords = np.array([self.get_point_in_json(self.coords_path_list[k]) for k in indexes])\n",
        "\n",
        "        return image, coords\n",
        "\n",
        "    def __get_list_from_dict(self, data: dict, size_img):\n",
        "        result = []\n",
        "        keys = data.keys()\n",
        "        dx = size_img[0]/self.image_size[0]\n",
        "        dy = size_img[1]/self.image_size[1]\n",
        "        for key in keys:\n",
        "            result.append(int(data[key][0]/dy))\n",
        "            result.append(int(data[key][1]/dx))\n",
        "            \n",
        "        return result                                                                                                                                                                                                           "
      ],
      "metadata": {
        "id": "Bf_UiEg-Cnnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 8"
      ],
      "metadata": {
        "id": "bj01QlrUNN0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = DataGenerator(train_path_images, train_path_json, batch_size=batch)\n",
        "valid_generator = DataGenerator(train_path_images, train_path_json, batch_size=batch)"
      ],
      "metadata": {
        "id": "jCRGOJpLuHOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line in train_generator:\n",
        "    for i in range(8):\n",
        "        img = line[0][i].numpy().copy()\n",
        "        cv2.circle(img, (line[1][i][0],line[1][i][1]),10,(255,0,0),-1)\n",
        "        cv2.circle(img, (line[1][i][2],line[1][i][3]),10,(255,0,0),-1)\n",
        "        cv2.circle(img, (line[1][i][4],line[1][i][5]),10,(255,0,0),-1)\n",
        "        cv2.circle(img, (line[1][i][6],line[1][i][7]),10,(255,0,0),-1)\n",
        "        cv2_imshow(img*255)\n",
        "        print(line[1][i])\n",
        "    break"
      ],
      "metadata": {
        "id": "tAXf3p6INtpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg.trainable = False\n",
        "# flatten the max-pooling output of VGG\n",
        "flatten = vgg.output\n",
        "flatten = Flatten()(flatten)\n",
        "# construct a fully-connected layer header to output the predicted\n",
        "# bounding box coordinates\n",
        "bboxHead = Dense(256, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(4, activation=\"sigmoid\")(bboxHead)\n",
        "# construct the model we will fine-tune for bounding box regression\n",
        "model = Model(inputs=vgg.input, outputs=bboxHead)\n"
      ],
      "metadata": {
        "id": "UdhTHqh3whBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG19(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(512, 512,3)))"
      ],
      "metadata": {
        "id": "CsV-D6YnvZ0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard"
      ],
      "metadata": {
        "id": "fJ5e-q3UNuzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL\n",
        "\n",
        "# INPUT \n",
        "inputs = tf.keras.layers.Input(shape=(512,512,1))\n",
        "\n",
        "conv_1 = tf.keras.layers.Conv2D(name = 'conv_1', filters = 16, kernel_size = 3, strides = 2, padding = 'same', activation = tf.keras.activations.relu)(inputs)\n",
        "conv_1 = tf.keras.layers.BatchNormalization()(conv_1) \n",
        "\n",
        "conv_2 = tf.keras.layers.Conv2D(name = 'conv_2', filters = 32, kernel_size = 3, strides = 2, padding = 'same', activation = tf.keras.activations.relu)(conv_1)\n",
        "conv_2 = tf.keras.layers.BatchNormalization()(conv_2) \n",
        "\n",
        "conv_3 = tf.keras.layers.Conv2D(name = 'conv_3', filters = 128, kernel_size = 3, strides = 2, padding = 'same', activation = tf.keras.activations.relu)(conv_2)\n",
        "conv_3 = tf.keras.layers.BatchNormalization()(conv_3) \n",
        "\n",
        "conv_4 = tf.keras.layers.Conv2D(name = 'conv_4', filters = 256, kernel_size = 3, strides = 2, padding = 'same', activation = tf.keras.activations.relu)(conv_3)\n",
        "conv_4 = tf.keras.layers.BatchNormalization()(conv_4) \n",
        "\n",
        "conv_5 = tf.keras.layers.Conv2D(name = 'conv_5', filters = 256, kernel_size = 3, strides = 2, padding = 'same', activation = tf.keras.activations.relu)(conv_4)\n",
        "conv_5 = tf.keras.layers.BatchNormalization()(conv_5) \n",
        "\n",
        "flat = tf.keras.layers.Flatten()(conv_5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "hidden_1 = tf.keras.layers.Dense(4096, activation='sigmoid')(flat)\n",
        "hidden_1 = tf.keras.layers.BatchNormalization()(hidden_1)\n",
        "hidden_2 = tf.keras.layers.Dense(4096, activation='sigmoid')(hidden_1)\n",
        "hidden_2 = tf.keras.layers.BatchNormalization()(hidden_2)\n",
        "\n",
        "\n",
        "\n",
        "output = tf.keras.layers.Dense(8, activation='relu')(hidden_2)"
      ],
      "metadata": {
        "id": "iiTb47TAf5gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs = inputs, outputs = output)"
      ],
      "metadata": {
        "id": "-UH5cEJm5q3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "S65e9snsvhX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "WAg8ag7vhEYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam' , loss=tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy', 'mse', 'mean_absolute_error'])"
      ],
      "metadata": {
        "id": "hGiZCK7hhK6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "          ModelCheckpoint(\"files/model.h5\"),\n",
        "          ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
        "          CSVLogger(\"files/data.csv\"),\n",
        "          TensorBoard(),\n",
        "          EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=False)\n",
        "     ]"
      ],
      "metadata": {
        "id": "xOxjuMMNhUkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator, validation_data= valid_generator,\n",
        "        epochs=250,\n",
        "        callbacks=callbacks, )"
      ],
      "metadata": {
        "id": "eg_o-Ru4hbWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3s1WucRhcWA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}